{
    "dataset_reader": {
      "type": "processed_document_reader"
    },
    "train_data_path": "data/semi_supervised/train_20k_labelled.filtered.jsonl",
    "validation_data_path": "data/semi_supervised/valid.filtered.jsonl",
    "vocabulary": {
        "max_vocab_size": {
            "stopless": 2000,
            "full": 10000
        }
    },
    "model": {
      "type": "BOWTopicModelSemiSupervised2",
      "background_data_path": "data/semi_supervised/train_20k_labelled.bgfreq.json",
      "alpha": 100,
      "update_bg": false,
      "input_embedder": {
        "full": {
          "type": "embedding",
          "embedding_dim": 300,
          "trainable": true,
          "vocab_namespace": "full"
        }
      },
      "filtered_embedder": {
        "filtered": {
            "type": "embedding",
            "embedding_dim": 300,
            "pretrained_file": "/Users/dangitstam/Research/glove/glove.6B.300d.txt",
            "trainable": true,
            "vocab_namespace": "stopless"
          }
      },
      "encoder": {
        "type": "boe",
        "embedding_dim": 300
      },
      "vae": {
        "apply_batchnorm": {
            "mu": false,
            "sigma": false
        },
        "encoder": {
          "input_dim": 2004,
          "num_layers": 1,
          "hidden_dims": [500],
          "activations": ["linear"],
          "dropout": 0.3
        },
        "decoder": {
          "input_dim": 10,
          "num_layers": 1,
          "hidden_dims": [2004],
          "activations": ["tanh"]
        },
        "mu_projection": {
          "input_dim": 500,
          "num_layers": 1,
          "hidden_dims": [10],
          "activations": ["linear"],
          "dropout": 0.3
        },
        "log_variance_projection": {
          "input_dim": 500,
          "num_layers": 1,
          "hidden_dims": [10],
          "activations": ["linear"],
          "dropout": 0.3
        }
      },
      "classification_layer": {
        "input_dim": 300,
        "num_layers": 1,
        "hidden_dims": [2],
        "activations": ["linear"],
        "dropout": 0.3
      }
    },
    "iterator": {
      "type": "basic",
      "batch_size": 100
    },
    "trainer": {
      "num_epochs": 200,
      "cuda_device": -1,
      "optimizer": {
        "type": "adam",
        "lr": 0.001,
        "weight_decay": 0.0001
      }
    }
  }
  
